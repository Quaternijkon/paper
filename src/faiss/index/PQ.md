# Product Quantization

PQå¹¶ä¸æ˜¯ä¸€ç§ç´¢å¼•ï¼Œè€Œæ˜¯åˆ›å»ºå¤åˆç´¢å¼•ä¸­çš„ä¸€ç§Fine quantizerã€‚

## Introduction

<iframe width="560" height="315" src="https://www.youtube.com/embed/t9mRf2S5vDI?si=-y4TyDmvil9q9cd5" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

å‘é‡ç›¸ä¼¼æ€§æœç´¢å¯èƒ½éœ€è¦å¤§é‡å†…å­˜ï¼Œéšç€æ•°æ®é›†å¤§å°çš„ä¸æ–­å¢åŠ ï¼Œå†…å­˜å ç”¨ä¼šå˜å¾—éš¾ä»¥æ‰¿å—ã€‚PQå¯ä»¥å¤§å¹…å‹ç¼©é«˜ç»´å‘é‡ï¼Œç”šè‡³èƒ½å‡å°‘97%çš„å†…å­˜å ç”¨ã€‚ï¼ˆBut at what costï¼Ÿï¼‰

### Quantization & Dimensionality-reduction

é‡åŒ–ä¸é™ç»´ä¸åŒï¼Œé™ç»´çš„ç›®çš„æ˜¯å¾—åˆ°ä¸€ä¸ªä½ç»´å‘é‡ï¼Œè€Œé‡åŒ–çš„ç›®çš„æ˜¯å¾—åˆ°ä¸€ä¸ªä½ç²¾åº¦å‘é‡ã€‚

> [!TIP]
> æ¯”å¦‚æˆ‘æœ‰ä¸€ä¸ª128ç»´çš„FP32å‘é‡ï¼Œæˆ‘å¯ä»¥å°†å…¶é™ç»´åˆ°64ç»´ï¼ˆä¸æ˜¯ç®€å•çš„è£åˆ‡ï¼Œæ¯”å¦‚ä½¿ç”¨PCAä¸»æˆåˆ†åˆ†æï¼‰ï¼Œä¹Ÿå¯ä»¥å°†å…¶é‡åŒ–ä¸ºINT8å‘é‡ã€‚æ¯«æ— ç–‘é—®è¿™ä¸¤ç§æ–¹æ³•éƒ½å‡å°‘äº†å‘é‡çš„å ç”¨ï¼Œè€Œä¸”éƒ½æŸå¤±äº†ä¿¡æ¯ã€‚
> ![pqex](./img/pqex.jpg)
> é™ç»´ç¼©å°äº†å‘é‡çš„ç»´åº¦ï¼Œé‡åŒ–ç¼©å°äº†èƒ½è¡¨ç¤ºçš„èŒƒå›´ã€‚
> ä½†æ˜¯PQå¹¶ä¸æ˜¯ç®€å•çš„å°†æ¯ä¸ªç»´åº¦çš„ä¿¡æ¯é‡åŒ–æˆæ›´ä½ç²¾åº¦çš„è¡¨ç¤ºã€‚ç²—ç•¥åœ°è¯´ï¼ŒPQå…ˆå°†å‘é‡åˆ†æˆå‡ ä¸ªå­å‘é‡ï¼Œæ¯ä¸ªå­å‘é‡ç”¨å®ƒä»¬æ‰€åœ¨çš„ç°‡çš„IDæ¥è¡¨ç¤ºã€‚

### How PQ works

1. æˆ‘æœ‰ä¸€äº›128ç»´çš„å‘é‡ã€‚
2. æŒ‰32ç»´åˆ‡åˆ†æˆ4ä¸ªå­å‘é‡ã€‚
3. å¯¹æ‰€æœ‰128ç»´å‘é‡çš„ç›¸åŒä½ç½®ä¸Šçš„32ç»´å­å‘é‡è¿›è¡Œèšç±»ï¼Œä¾‹å¦‚å¾—åˆ°128ä¸ªç°‡ã€‚
4. ç”¨æ¯ä¸ªå­å‘é‡æ‰€åœ¨ç°‡çš„IDæ¥è¡¨ç¤ºè¿™ä¸ªå­å‘é‡ã€‚ï¼ˆè¿™æ ·æˆ‘ä»¬å°±èƒ½ç”¨2å­—èŠ‚è¡¨ç¤ºä¸€ä¸ªå­å‘é‡ï¼‰
5. æœ€ç»ˆ128ç»´çš„å‘é‡å¯ä»¥ç”¨8å­—èŠ‚è¡¨ç¤ºã€‚

![pq](./img/pq.png)

**åˆ‡åˆ†å‘é‡**
```python
x = [1, 8, 3, 9, 1, 2, 9, 4, 5, 4, 6, 2]

m = 4
D = len(x)
# ensure D is divisable by m
assert D % m == 0
# length of each subvector will be D / m (D* in notation)
D_ = int(D / m)

# now create the subvectors
u = [x[row:row+D_] for row in range(0, D, D_)]
print(u)
```
**åˆ›å»ºèšç±»**
    ä¸ºæ–¹ä¾¿èµ·è§ï¼Œè¿™é‡Œéšæœºç”Ÿæˆèšç±»ä¸­å¿ƒã€‚
    å†ç°å€¼ï¼ˆreproduction valuesï¼‰ï¼šç”¨\(c_{ji}\)è¡¨ç¤ºç¬¬\(j\)ä¸ªå­å‘é‡çš„ç¬¬\(i\)ä¸ªæ‰€é€‰è´¨å¿ƒã€‚
```python
k = 2**5
assert k % m == 0
k_ = int(k/m)
print(f"{k=}, {k_=}")

from random import randint

c = []  # our overall list of reproduction values
for j in range(m):
    # each j represents a subvector (and therefore subquantizer) position
    c_j = []
    for i in range(k_):
        # each i represents a cluster/reproduction value position *inside* each subspace j
        c_ji = [randint(0, 9) for _ in range(D_)]
        c_j.append(c_ji)  # add cluster centroid to subspace list
    # add subspace list of centroids to overall list
    c.append(c_j)
```
    å®šä¹‰å‡½æ•°è®¡ç®—L2è·ç¦»å’Œå¯»æ‰¾æœ€è¿‘é‚»å±…
    `ids`è®°å½•è·ç¦»æ¯ä¸ªå­å‘é‡æœ€è¿‘çš„è´¨å¿ƒçš„æ ‡è¯†ç¬¦ã€‚
```python
def euclidean(v, u):
    distance = sum((x - y) ** 2 for x, y in zip(v, u)) ** .5
    return distance

def nearest(c_j, u_j):
    distance = 9e9
    for i in range(k_):
        new_dist = euclidean(c_j[i], u_j)
        if new_dist < distance:
            nearest_idx = i
            distance = new_dist
    return nearest_idx

ids = []
for j in range(m):
    i = nearest(c[j], u[j])
    ids.append(i)
print(ids)
```
    qæ˜¯ç”¨è´¨å¿ƒåæ ‡è¡¨ç¤ºçš„å‘é‡ã€‚
```python
q = []
for j in range(m):
    c_ji = c[j][ids[j]]
    q.extend(c_ji)

print(q)
```

~~~admonish example

å‡è®¾ï¼š
```python
u = [[1, 8, 3], [9, 1, 2], [9, 4, 5], [4, 6, 2]]
```
æˆ‘ä»¬æœ‰ `m=4` ä¸ªå­ç©ºé—´ï¼Œæ¯ä¸ª `u[j]` éƒ½æœ‰ `k_=8` ä¸ªå¯é€‰çš„ç°‡å¿ƒ `c[j]`ã€‚

ä»£ç æ‰§è¡Œ `nearest(c[j], u[j])`ï¼Œæ‰¾åˆ° `u[j]` åœ¨ `c[j]` é‡Œçš„æœ€è¿‘ç°‡å¿ƒï¼š
```python
ids = [7, 1, 5, 3]
```
è¿™æ„å‘³ç€ï¼š
- `u[0] = [1, 8, 3]` åœ¨ `c[0]` é‡Œæœ€æ¥è¿‘ `c[0][7]`
- `u[1] = [9, 1, 2]` åœ¨ `c[1]` é‡Œæœ€æ¥è¿‘ `c[1][1]`
- `u[2] = [9, 4, 5]` åœ¨ `c[2]` é‡Œæœ€æ¥è¿‘ `c[2][5]`
- `u[3] = [4, 6, 2]` åœ¨ `c[3]` é‡Œæœ€æ¥è¿‘ `c[3][3]`

ç„¶å `q` é€šè¿‡ `ids` æ‰¾åˆ°è¿™äº›ç°‡å¿ƒï¼Œå¹¶æ‹¼æ¥ï¼š
```python
q = []
for j in range(m):
    c_ji = c[j][ids[j]]  # å–å‡ºæœ€è¿‘çš„ç°‡å¿ƒ
    q.extend(c_ji)       # å±•å¼€å¹¶æ‹¼æ¥
```
æœ€ç»ˆï¼š
```python
q = c[0][7] + c[1][1] + c[2][5] + c[3][3]
```
~~~

~~~admonish success
```python
x = [1, 8, 3, 9, 1, 2, 9, 4, 5, 4, 6, 2]

m = 4
D = len(x)
# ensure D is divisable by m
assert D % m == 0
# length of each subvector will be D / m (D* in notation)
D_ = int(D / m)

# now create the subvectors
u = [x[row:row+D_] for row in range(0, D, D_)]
print(u)

k = 2**5
assert k % m == 0
k_ = int(k/m)
print(f"{k=}, {k_=}")

from random import randint

c = []  # our overall list of reproduction values
for j in range(m):
    # each j represents a subvector (and therefore subquantizer) position
    c_j = []
    for i in range(k_):
        # each i represents a cluster/reproduction value position *inside* each subspace j
        c_ji = [randint(0, 9) for _ in range(D_)]
        c_j.append(c_ji)  # add cluster centroid to subspace list
    # add subspace list of centroids to overall list
    c.append(c_j)
    
def euclidean(v, u):
    distance = sum((x - y) ** 2 for x, y in zip(v, u)) ** .5
    return distance

def nearest(c_j, u_j):
    distance = 9e9
    for i in range(k_):
        new_dist = euclidean(c_j[i], u_j)
        if new_dist < distance:
            nearest_idx = i
            distance = new_dist
    return nearest_idx

ids = []
for j in range(m):
    i = nearest(c[j], u[j])
    ids.append(i)
print(ids)

q = []
for j in range(m):
    c_ji = c[j][ids[j]]
    q.extend(c_ji)

print(q)
```
~~~

## Implementation in Faiss

<iframe width="560" height="315" src="https://www.youtube.com/embed/BMYBwbkbVec?si=jUPoNcsXxWUDcUja" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦è·å–æ•°æ®ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Sift1M æ•°æ®é›†ã€‚

```python
import shutil
import urllib.request as request
from contextlib import closing

# first we download the Sift1M dataset
with closing(request.urlopen('ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz')) as r:
    with open('sift.tar.gz', 'wb') as f:
        shutil.copyfileobj(r, f)

import tarfile

# the download leaves us with a tar.gz file, we unzip it
tar = tarfile.open('sift.tar.gz', "r:gz")
tar.extractall()

import numpy as np

# now define a function to read the fvecs file format of Sift1M dataset
def read_fvecs(fp):
    a = np.fromfile(fp, dtype='int32')
    d = a[0]
    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')

# data we will search through
wb = read_fvecs('./sift/sift_base.fvecs')  # 1M samples
# also get some query vectors to search with
xq = read_fvecs('./sift/sift_query.fvecs')
# take just one query (there are many in sift_learn.fvecs)
xq = xq[0].reshape(1, xq.shape[1])

xq.shape # (1, 128)

wb.shape # (1000000, 128)
```

### IndexPQ

```python
import faiss

D = xb.shape[1]
m = 8
assert D % m == 0
nbits = 8  # number of bits per subquantizer, k* = 2**nbits
index = faiss.IndexPQ(D, m, nbits)
```

ç´¢å¼•éœ€è¦3ä¸ªå‚æ•°ï¼š
- `D`ï¼šå‘é‡çš„ç»´åº¦
- `m`ï¼šå­å‘é‡çš„æ•°é‡
- `nbits`ï¼šæ¯ä¸ªå­å‘é‡çš„ä½æ•°

> [!Tip]
> `nbits` å®šä¹‰äº†æ¯ä¸ªå­é‡åŒ–å™¨å¯ä»¥ä½¿ç”¨çš„ä½æ•°,ä¾‹å¦‚ `nbits` ä¸º 11ï¼Œæ¯ä¸ªå­ç©ºé—´æœ‰2048è´¨å¿ƒã€‚

å› ä¸ºä½¿ç”¨çš„æ˜¯ä½¿ç”¨èšç±»çš„ PQï¼Œæ‰€ä»¥å¿…é¡»é¢„å…ˆè®­ç»ƒæˆ‘ä»¬çš„ç´¢å¼•ã€‚ï¼ˆè¿™é‡Œç›´æ¥ä½¿ç”¨ `xb` è¿›è¡Œè®­ç»ƒï¼‰,ç„¶åå†å°†å‘é‡æ·»åŠ åˆ°ç´¢å¼•ä¸­è¿›è¡Œæœç´¢

```python
index.is_trained # False
index.train(xb)  # PQ training can take some time when using large nbits
index.is_trained # True
index.add(xb)

dist, I = index.search(xq, k) # åœ¨distä¸­è¿”å›è·ç¦»ï¼Œåœ¨Iä¸­è¿”å›ç´¢å¼•ã€‚

%%timeit
index.search(xq, k) # 1.49 ms Â± 49.1 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)
```

ä½¿ç”¨L2ç´¢å¼•ä½œä¸ºåŸºå‡†ï¼Œè®¡ç®—å¬å›ç‡

```python
l2_index = faiss.IndexFlatL2(D)
l2_index.add(xb)

%%time
l2_dist, l2_I = l2_index.search(xq, k) # CPU times: user 46.1 ms, sys: 15.1 ms, total: 61.2 ms, Wall time: 15 ms

sum([1 for i in I[0] if i in l2_I]) # 50
```

æœç´¢è¡¨ç°éƒ¨åˆ†å°†æ”¾åœ¨[Comparison](../comparison.md)ä¸­è®¨è®ºã€‚

### IndexIVFPQ

ä¸ºäº†è¿›ä¸€æ­¥åŠ å¿«æœç´¢æ—¶é—´ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ å¦ä¸€ä¸ªæ­¥éª¤â€”â€”ä½¿ç”¨ IVF ç´¢å¼•ï¼Œå®ƒå°†å‡å°‘æœç´¢ä¸­æ¯”è¾ƒçš„å‘é‡ã€‚

é¦–å…ˆåˆå§‹åŒ–IVFPQç´¢å¼•ï¼š

```python
vecs = faiss.IndexFlatL2(D)

nlist = 2048  # how many Voronoi cells (must be >= k* which is 2**nbits)
nbits = 8  # when using IVF+PQ, higher nbits values are not supported
index = faiss.IndexIVFPQ(vecs, D, nlist, m, nbits)
```

è®­ç»ƒï¼Œæ·»åŠ ï¼Œæœç´¢...

```python
index.train(xb)
index.add(xb)
dist, I = index.search(xq, k)
%%timeit
index.search(xq, k) # 86.3 Âµs Â± 15 Âµs per loop (mean Â± std. dev. of 7 runs, 10000 loops each)
sum([1 for i in I[0] if i in l2_I]) # 34
```

æœç´¢é€Ÿåº¦ä»1.49msé™ä½åˆ°86.3Âµsï¼Œä½†æ˜¯å¬å›ç‡ä»50%é™ä½åˆ°34%ã€‚åœ¨ç»™å®šç­‰æ•ˆå‚æ•°çš„æƒ…å†µä¸‹ï¼ŒIndexPQ å’Œ IndexIVFPQ éƒ½åº”è¯¥èƒ½å¤Ÿè·å¾—ç›¸åŒçš„å¬å›ç‡æ€§èƒ½ã€‚

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæé«˜å¬å›ç‡çš„åŠæ³•æ˜¯æé«˜nprobeå‚æ•°ã€‚ï¼ˆå½“nprobe=nlistæ—¶ï¼ŒIndexIVFPQé€€åŒ–ä¸ºIndexPQï¼‰

| nprobe | å¬å›ç‡ | æ—¶å»¶ |
|---|---|---|
| 1 | 34 | 86.3Âµs |
| 2 | 39 |  |
| 48 | 50 |  |
| 2048 | 50 | 1.49ms |

## Conclusion

|Index|é«˜å¬å›|ä½æ—¶å»¶|ä½å†…å­˜|
|---|---|---|---|
|Flat|ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢|ğŸ”´|ğŸ”´|
|PQ|ğŸŸ¡ğŸŸ¡ğŸŸ¡ğŸŸ¡|ğŸŸ¡ğŸŸ¡ğŸŸ¡|ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢|
|IVFPQ|ğŸŸ¡ğŸŸ¡ğŸŸ¡ğŸŸ¡|ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢|ğŸŸ¡ğŸŸ¡ğŸŸ¡ğŸŸ¡|
